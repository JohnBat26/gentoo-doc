<?xml version="1.0" encoding="utf-8"?>
<article xmlns="http://docbook.org/ns/docbook" version="5.0" xml:id="linuxndi">
 <articleinfo>
  <author>
   <firstname>Артём</firstname>
   <surname>Капитула</surname>
  </author>
  <pubdate>2007</pubdate>
  <title>Linux не для идиотов</title>
  <titleabbrev>Linux не для идиотов</titleabbrev>
  <abstract>
   <para>С версии: 1.1</para>
   <para>Обновлено в версии: 2.0</para>
   <para>
    Ccылка на оригинал:
    <ulink url="http://www.myfotomx.com/linuxndi.html">myfotomx.com</ulink>
   </para>
  </abstract>
 </articleinfo>

 <section xml:id="overview_linuxndi">
  <info>
   <title>Предисловие</title>
  </info>
  <para>
   Я много лет работал с Linux, и, общаясь со многими единомышленниками, сделал один странный вывод: нам
   катастрофически не
   хватает
   документации. Причем не инструкций вида «сделайте так и вот так» и не справочных руководств,
   а некоторого «мостика»
   между
   новичком, который
   видел только графическую оболочку подобную GNOME или KDE, и
   профессионалом, который может
   скомпилировать
   необходимый ему драйвер, даже если
   этот драйвер упорно сопротивляется.</para>
  <para>Соответственно, я попытался сделать попытку написать книжку (хотя на книгу этот материал не
   тянет, скорей
   на
   методичку), которая позволила бы сравнительно просто перейти с пользовательского уровня знакомства с
   Linux на более высокий
   уровень, не
   проходя по типичным ошибкам, и за сравнительно короткое время.</para>
  <para>
   Некоторое время я использовал фрагменты этой книги также как часть учебного курса в Челябинском Государственном
   университете
   (ЧелГУ) для
   того, чтобы мои студенты могли ориентироваться в системе несколько лучше, чем на уровне команд
   <emphasis role="bold"> ls/ps/exit</emphasis>
   . Конечно, если честно – как учебное пособие эта маленькая книга непригодна, но,
   как мне кажется, она неплохо подходит
   как
   дополнительная
   литература.
  </para>
  <para>
   Если у вас есть пожелания и дополнения – пишите мне почтой на
   <ulink url="mailto:dalt74@gmail.com">dalt74@gmail.com</ulink>
   , я постараюсь учесть ваши замечания в следующей редакции. Большое спасибо всем тем кто участвовал в рецензировании и
   помогал советами и
   замечаниями.
  </para>
  <para>Искренне ваш, Артем Капитула (no-dashi, dalth &amp; viking)</para>		
		<para>P.S. если вы будете распечатывать или выкладывать это пособие – пожалуйста, указывайте ссылку на автора и оригинальный источник, договорились?</para>		
		<para>P.P.S. пока что есть следующий to-do list: основы DNS, базовые настройки серверов и рабочих станций под типичные нужды. Ориентировочный срок следующей редакции – через три месяца.</para>						
	</section>
	<section xml:id="kernel_and_modules">
		<info>
			<title>Ядро и модули</title>
		</info>
		<para>
			Ядро Linux является единственным процессом, имеющим непосредственный доступ к аппаратуре – все остальные процессы обращаются к устройствам только через ядро. В ядре Linux можно выделить несколько важных подсистем: подсистему управления памятью; планировщик задач; подсистему VFS – виртуальную файловую систему и драйверы.
		</para>	
		<para>Подсистема управления памятью управляет распределением оперативной памяти между задачами, а также обслуживает файл подкачки, планировщик задач управляет разделением процессорного времени между задачами (процессами и нитями), подсистема VFS предназначена для обслуживания файловых операций.</para>
		<para>Драйверы предназначены для управления устройствами и поддержки различных протоколов. Существует две разновидности драйверов – статически подключенные в ядро драйверы и загружаемые модули; первые всегда загружены, вторые могут быть загружены при необходимости и выгружены, когда необходимость в них отпала. Каждый модуль и само ядро содержат сигнатуру версии – специальную метку, которая описывает версию ядра и некоторые опции, использованные при компиляции ядра. Кроме того, ядра версии 2.6 могут поддерживать цифровую подпись модулей. Это было сделано для повышения надежности системы – по умолчанию ядро не будет загружать и использовать драйверы, предназначенные для другой версии ядра, или собранные с другими опциями, поскольку это может привести к возникновению проблем. Версию ядра можно узнать с помощью команды <emphasis role="bold">uname</emphasis> :</para>
<screen>
$ <userinput>uname -r</userinput>
2.6.8.1
</screen>
		<para>В принципе, утилиты для работы с модулями поддерживают возможность загрузки модулей, собранных для другого ядра – но пользоваться этой возможностью следует с крайней осторожностью, поскольку это может привести к непредсказуемым последствиями – от ошибок ядра (kernel panic) и вплоть до странных потерь данных и непонятных ошибок, взявшихся на пустом месте.</para>
		<para>В большинстве дистрибутивов образ ядра располагается в каталоге /boot, а загружаемые модули ядра располагаются в /lib/modules/&lt;версия_ядра&gt;, там же располагается таблица зависимостей модулей, поскольку некоторые модули могут нуждаться для своей работы в других модулях (например, драйвер поддержки SCSI-дисков нуждается в драйвере поддержки SCSI – как следствие этого, если объекты какого-либо модуля используются другим драйвером, такой модуль невозможно выгрузить). Следующий листинг демонстрирует достаточно типичное содержание каталога модулей для ядер линейки 2.6:</para>
<screen>
$ <userinput> ls -l /lib/modules/2.6.8.1/</userinput>
total 616
lrwxrwxrwx   1 root root     18 Авг 27 15:36 build -&gt; /usr/src/linux
drwxr-xr-x  10 root root   4096 Окт  1 13:55 kernel
-rw-r--r--   1 root root 108680 Окт  1 13:56 modules.alias
-rw-r--r--   1 root root     69 Окт  1 13:56 modules.ccwmap
-rw-r--r--   1 root root 153967 Окт  1 13:56 modules.dep
-rw-r--r--   1 root root     73 Окт  1 13:56 modules.ieee1394map
-rw-r--r--   1 root root    357 Окт  1 13:56 modules.inputmap
-rw-r--r--   1 root root  16658 Окт  1 13:56 modules.isapnpmap
-rw-r--r--   1 root root  85093 Окт  1 13:56 modules.pcimap
-rw-r--r--   1 root root  68078 Окт  1 13:56 modules.symbols
-rw-r--r--   1 root root 150781 Окт  1 13:56 modules.usbmap
lrwxrwxrwx   1 root root     18 Окт  1 13:22 source -&gt; /usr/src/linux

$ <userinput>find /lib/modules/2.6.8.1/kernel -type f | head -20</userinput>		
/lib/modules/2.6.8.1/kernel/arch/i386/kernel/cpuid.ko
/lib/modules/2.6.8.1/kernel/arch/i386/kernel/microcode.ko
/lib/modules/2.6.8.1/kernel/arch/i386/kernel/msr.ko
/lib/modules/2.6.8.1/kernel/crypto/blowfish.ko
/lib/modules/2.6.8.1/kernel/crypto/deflate.ko
/lib/modules/2.6.8.1/kernel/crypto/md5.ko
/lib/modules/2.6.8.1/kernel/crypto/twofish.ko
/lib/modules/2.6.8.1/kernel/drivers/acpi/fan.ko
/lib/modules/2.6.8.1/kernel/drivers/acpi/processor.ko
/lib/modules/2.6.8.1/kernel/drivers/acpi/thermal.ko
/lib/modules/2.6.8.1/kernel/drivers/base/firmware_class.ko
/lib/modules/2.6.8.1/kernel/drivers/block/cryptoloop.ko
/lib/modules/2.6.8.1/kernel/drivers/block/loop.ko
/lib/modules/2.6.8.1/kernel/drivers/block/nbd.ko
/lib/modules/2.6.8.1/kernel/drivers/block/paride/epat.ko
/lib/modules/2.6.8.1/kernel/drivers/block/paride/paride.ko
/lib/modules/2.6.8.1/kernel/drivers/block/paride/pd.ko
/lib/modules/2.6.8.1/kernel/drivers/block/paride/pg.ko
/lib/modules/2.6.8.1/kernel/drivers/bluetooth/bcm203x.ko
/lib/modules/2.6.8.1/kernel/drivers/bluetooth/bfusb.ko
</screen>
		<para>Бинарные файлы модулей содержатся в подкаталоге kernel, и имеют расширение “.o” для ядер линейки 2.4 и расширение “.ko” для ядер линейки 2.6. В файлах modules.***map перечисляются символы (функции и переменные), экспортируемые модулями.</para>
		<para>Часто в одном каталоге с модулями содержатся ссылки на каталоги, в которых хранились исходные тексты ядра и в котором производилась сборка ядра (это ссылки source и build, соответственно). Эти ссылки, как правило, используются для того, чтобы скомпилировать модули или программы, которые зависят от версии ядра (например, эти ссылки используются при инсталляции модуля поддержки видеокарт nvidia).</para>
		<para>Учет взаимосвязей между загруженными модулями производится с помощью счетчика ссылок – модуль увеличивает свой счетчик ссылок как только какой-либо его объект начинает использоваться другими драйверами. Когда объекты модуля освобождаются, счетчик ссылок уменьшается. Модуль может быть выгружен, если число ссылок на него станет равно 0. В ядрах версии 2.6 существует возможность произвести принудительную выгрузку модуля даже если он используется, но этим пользоваться без крайней необходимости не рекомендуется, поскольку очень возможно возникновение ошибок.</para>
		<para>Ядро содержит множество переменных и функций, которые используются различными драйверами, и соответственно, если какой-либо драйвер должен обратиться к такому объекту, он должен знать его адрес. Некоторые драйверы также содержат переменные и функции, которые должны быть доступны другим драйверам, и адреса таких объектов тоже размещаются в специальной таблице. При загрузке модуля ядро и программа загрузки модулей устанавливает адреса всех объектов, в которых нуждается загружаемый модуль, и только после этого модуль может начать инициализацию.</para>
		<para>Загрузка модулей и их выгрузка осуществляются утилитами modprobe, insmod и rmmod. Программы modinfo и depmod предназначены для получения служебной информации о загружаемых модулях. В процессе своей работы эти утилиты опираются на конфигурационные файлы /etc/modprobe.conf (для ядер 2.6.X) или modules.conf (для ядер 2.4.X).</para>
	</section>
	<section xml:id="load_os">
		<info>
			<title>Загрузка операционной системы</title>
		</info>
		<para>Для компьютеров архитектуры x86 последовательность загрузки хорошо описана в специализированной литературе, но мы все-таки кратко ее повторим. После включения компьютера первым загружается BIOS. Он тестирует аппаратуру и инициализирует устройства. После этого BIOS прочитывает начальный сектор загрузочного жесткого диска (MBR), убеждается что он содержит код первичного загрузчика, и передает управление прочитанному коду. Кроме кода первичного загрузчика, начальный сектор также может содержать таблицу разделов жесткого диска.</para>
		<para>В задачи первичного загрузчика входит чтение основного кода загрузчика операционной системы и передача управления ему, после чего основная часть загрузчика может считать конфигурационный файл, загрузить ядро операционной системы, установить параметры для ядра и передать ядру управление. Ядро инициализирует драйверы, проверяет параметры и, опираясь на параметры, пытается смонтировать корневую файловую систему, после чего (если не было проинструктировано об ином) запускает программу /sbin/init. Дальнейшая работа init подробно описана во множестве книг и статей.</para>
		<para>В настоящий момент в мире Linux наиболее распространен загрузчик GRUB. Этот загрузчик состоит из нескольких частей – первичного загрузчкиа, собственно основного кода который организует интерфейс пользователя, и набора мини-драверов различных файловых систем, позволяющих прочесть необходимые файлы с файловой системы в момент когда операционная система еще недоступна. Каждая из этих компонент работает на одноим из двух этапов загрузки. Рассмотрим эти этапы:</para>
		<para>Этап 0 – здесь срабатывает первичный загрузчик GRUB. Он компактен и умещается в один блок жесткого диска, что позволяет при желании разместить его в MBR. В задачи кода stage_0 входит прочтение кода необходимого на следующем этапе (собственно кода загрузчика и мини-драйвера файловой системы где расположены основные файлы загрузчика), и передача управления прочитанному коду.</para>
		<para>Этап 1 – это на этом этапе первичным загрузчиком в память уже загружен основной код загрузчика, а также мини-драйвер файловой системы, на которой расположены конфигурационные файлы загрузчика, ядро и необходимые драйверы. Основной код, используя функции мини-драйвера, прочитывает конфигурационный файл и организует диалог с пользователем. В зависимости от выбора пользователя, используя мини-драйвер файловой системы, с диска прочитываются файлы ядра и необходимых драйверов, после чего управление передается ядру. Как вариант, пользователь может отказаться от загрузки Linux и инструктировать GRUB прочесть загрузочный сектор некоторого раздела жесткого диска и передать управление ему.</para>
		<para>Первичный загрузчик из состава GRUB может быть расположен как в MBR, так и в загрузочном секторе какого-либо раздела жесткого диска – или даже храниться в файле и быть вызван из другого загрузчика (например NTLOADER).</para>
		<para>Нередко случаются ситуации, когда корневая файловая система располагается на устройстве, чей драйвер скомпилирован в виде модуля, или драйвер корневой файловой системы скомпилирован в виде модуля. Получается замкнутый круг – чтобы смонтировать корневую файловую систему систему, необходимо прочесть драйвер, а чтобы прочесть драйвер – нужно смонтировать корневую файловую систему. Чтобы разорвать этот порочный круг, в Linux была введен поддержка initrd – INITial RamDisk.</para>
		<para>Initial ramdisk – это файл, который прочитывается загрузчиком ОС и загружается в память вместе с ядром. Ядро интерпретирует фрагмент памяти, куда загружен этот файл, как блочное устройство с помощью специального драйвера, статически вкомпилированного в ядро. После инициализации статически скомпилированных драйверов ядро монтирует файловую систему, хранящуюся в initrd и загружает с нее драйверы и запускает программы, необходимые для монтирования корневой файловой системы.</para>
		<para>Обычно файл с образом ядра хранится в каталоге /boot и называется vmlinuz-&lt;версия&gt;, там же располагается файл initrd-&lt;версия&gt;.img, содержащий образ файловой системы initrd. Для каждой версии ядра необходим свой образ initrd, в который включены модули для этой версии ядра. В большинстве случаев образ initrd поставляется в бинарном пакете вместе с ядром, или автоматически создается в процессе построения ядра из исходных текстов в момент выполнения команды make install, если же возникает ситуация, когда необходимо повторно собрать образ initrd (например, в сервере сменили SCSI-контроллер), можно воспользоваться специальной командой mkinitrd, позволяющей произвести повторную генерацию initrd:</para>
<screen>
$ <userinput> mkinitrd /tmp/initrd-2.4.8.1.img 2.6.8.1</userinput>
$ <userinput> cp /tmp/initrd-2.4.8.1.img /boot</userinput>
$ <userinput> reboot</userinput>
</screen>

		<para>Для Linux существует два основных загрузчика – LILO и GRUB. Второй является более поздней разработкой и немного удобней в
			использовании, а LILO используется по историческим или личным причинам (например, он нравится системному администратору),
			либо в некоторых случаях, когда требуются специфичные для LILO функции. Для более подробной справки лучше обратиться к
			справочному руководству (man grub, man lilo).</para>
		<para>Из интересных особенностей GRUB и LILO следует отметить то, что и оба этих загрузчика, и ядро оперируют термином корневой
			файловой системы – но если с точки зрения ядра эта та файловая система, которая содержит программу /sbin/init, то с точки зрения
			обоих загрузчиков корневой файловой системой является та, которая содержит образ ядра и файл initrd.</para>
	</section>
	
	<section xml:id="memory_organization">
		<info>
			<title>Организация памяти</title>
		</info>
		<para>Подсистема виртуальной памяти управляет распределением оперативной памяти между задачами (процессами). Каждая задача
			считает, что ей выделен непрерывный участок памяти максимального размера, поддерживаемого на соответствующей архитектуре
			(для архитектуры x86 это 4GB). Из них первый гигабайт резервируется для себя ядром, второй отдается под код программы и
			разделяемые библиотеки (оба этих фрагмента ядром защищаются), а два последних гигабайта отдаются собственно программе под
			ее данные – но это только то, как видит это все программа.</para>
		<para>На самом же деле программа занимает только тот объем памяти, с которым она реально работает. Большинство памяти существует
			только “на бумаге”, т.е. будет предоставлена программе в тот момент, когда она обратится в эту область. Ядро распределяет память
			страницами фиксированного размера. Процедура, когда страница оперативной памяти объявляется частью адресного пространства
			процесса, называется отображением этой страницы в адресное пространство процесса.</para>
		<para>Соответственно, ядро отображает реально используемые страницы в виртуальное адресное пространство процесса. Когда процесс
			обращается к некоторой странице своего адресного пространства, ядро проверяет, имеет ли он право на доступ к этой странице, и
			если проверка пройдена и доступ получен, то ядро переадресовывает обращение на реальный адрес этой страницы. Если это первое
			обращение к странице, ядро попытается найти свободную страницу и в случае успеха отобразит ее в адресное пространство
			соответствующего процесса. Размер страницы фиксирован архитектурой процессора, и для x86 ее размер составляет 4096
			байт.</para>
		<para>Если случается ситуация, когда свободных страниц больше нет, но существует файл подкачки, ядро может убрать одну из
			наиболее долго не использовавшихся страниц в файл подкачки, и освободившуюся физическую страницу отдать запросившему
			память процессу. Если же нет ни незанятого пространства в файле подкачки, ни свободных страниц RAM, то развитие событий может
			быть следующим: либо запросивший память процесс прерван и “убит” системой, либо какой-то другой из процессов (это
			определяется специфическими алгоритмами) будет “убит” ядром, и освободившаяся память будет передана запросившему память
			процессу.</para>
		<para>На самом деле большинством действий занимается одна из подсистем процессора, называемая MMU – Memory Management Unit, и
			в действительности ядро просто полагается на его работу и вмешивается в нее только для проведения операций пейджинга
			(подгрузки/выгрузки страниц в SWAP-файл), или когда возникает ошибка доступа к странице.</para>
		<para>Ограничение адресного пространства в 4GB не означает, что система не сможет адресовать более этого объема памяти. На
			платформе x86 ядро Linux может использовать до 64GB, а ограничение в 4GB накладывается лишь на размер адресного
			пространства процесса.</para>
	</section>
	<section xml:id="system_5_shared_memory">
		<info>
			<title>System V shared memory</title>
		</info>
		<para>Linux поддерживает стандартную для всех UNIX-подобных операционных систем организацию разделяемой памяти. Пользовательские приложения могут создавать сегменты разделяемой памяти, которые могут быть присоединены к некоторому фрагменту адресного пространства процесса. Любой процесс, имеющий достаточные права доступа, может присоединиться к сегменту разделяемой памяти, и отобразить его в свое адресное пространство, начиная с некоторого адреса.</para>
		
		<para>Если в приведенной схеме любой из процессов изменит содержимое памяти в области, занимаемой отображением одного из сегментов, то же самое изменение произойдет в адресном пространстве другого процесса, поскольку соответствующий сегмент существует в одном экземпляре и отображен в адресное пространство обоих процессов.</para>
		<para>Кроме System V IPC ядро Linux также поддерживает другие объекты IPC, в частности семафоры и очереди сообщений. Каждый объект System V IPC идентифицируется уникальным ключом. Просмотреть список всех объектов IPC можно командой ipcs. Команда ipcrm позволяет удалять объекты IPC, которые по каким-либо причинам остались не освобожденными после завершения создавшего их процесса – например, такая ситуация может возникнуть после аварийного завершения работы СУБД Oracle, Informix или DB2.</para>
		<para>Соответственно, перед перезапуском процесса системный администратор с помощью команды ipcrm должен освободить неиспользуемые объекты IPC, поскольку стартующее приложение не сможет их повторно создать и не будет корректно работать.</para>
		<para>Для каждого объекта IPC система устанавливает права доступа, как если бы это был файл (т.е. для каждого объекта IPC можно устанавливать набор прав ugo/rwx, но в отличие от обычных файлов сменить права доступа для IPC-объектов можно только вызывая специализированные функции, предназначенные для работы с такими объектами.</para>
		<mediaobject>
			<imageobject>
				<imagedata fileref="images/System_V_shared_memory.png" format="PNG"  width="60%" align="center"/>
			</imageobject>
			<textobject>
				<phrase>System V shared memory</phrase>	 
			</textobject>
			<caption>
				<para><emphasis role="strong">System V shared memory.</emphasis></para>
			</caption>
    		</mediaobject>
		<screen>
$ <userinput> ipcs</userinput>

------ Shared Memory Segments --------
key        shmid      owner      perms      bytes      nattch     status      
0x00000000 0          oracle    640        4194304    10                      
0x00000000 32769      oracle    640        20971520   10                      
0x00000000 65538      oracle    640        29360128   10                      
0x0d3c24a0 98307      oracle    640        29360128   50                      
0x00000000 13697028   root      777        49152      1                       
0x00000000 13729797   root      777        16384      1                       
0x000004d2 13795334   dalth     666        1008       2                       
0x00000000 14286866   root      644        790528     2          dest         
0x00000000 21823507   dalth     600        393216     2          dest         
0x00000000 21921814   root      644        122880     2          dest         
0x00000000 14516249   root      644        151552     1          dest         

------ Semaphore Arrays --------
key        semid      owner      perms      nsems     
0x0b4f657c 262147     oracle    640        154       
0x000004d2 458756     dalth     666        1         

------ Message Queues --------
key        msqid      owner      perms      used-bytes   messages 
</screen>
<para>Поддержка System V IPC позволяет сравнительно легко переносить на Linux приложения, написанные для других UNIX-систем.</para>
	</section>
 <section xml:id="file_system">
  <info>
   <title>Файловая система</title>
  </info>
	<section xml:id="vfs">
		<info>
			<title>Виртуальная файловая система</title>
		</info>
		<para>VFS и драйверы файловых систем являются одной из важнейших составляющих ядра. Для того, чтобы получить доступ к файлам,
			хранящимся на каком-либо устройстве хранения данных, необходимо, чтобы в ядро был загружен драйвер соответствующей
			файловой системы, и файловая система была смонтирована. Драйвера всех файловых систем поддерживают набор стандартных
			функций: открыть файл по имени, записать данные в файл, прочитать данные из файла, закрыть файл, удалить файл и т.д.</para>
		
		<para>Уточним, что драйвера файловых систем не занимаются кэшированием, этим занимается VFS.</para>
		<para>При первоначальной загрузке драйвер файловой системы регистрирует в VFS имя файловой системы и те функции, которые
			предназначены для выполнения стандартных файловых операций. Впоследствии при обращении к файлу на какой-либо файловой
			системе VFS будет переадресовывать обращение на соответствующую функцию, если таковая была зарегистрирована драйвером.
			Посмотреть список обслуживаемых ядром файловых систем можно в файле /proc/filesystems:</para>
<screen>
$ <userinput> cat /proc/filesystems </userinput>
nodev   sysfs
nodev   rootfs
nodev   bdev
nodev   proc
nodev   sockfs
nodev   usbfs
nodev   usbdevfs
nodev   futexfs
nodev   tmpfs
nodev   pipefs
nodev   eventpollfs
nodev   devpts
ext2
nodev   ramfs
nodev   hugetlbfs
iso9660
nodev   devfs
nodev   mqueue
ext3
nodev   rpc_pipefs
nodev   nfsd
nodev   smbfs
</screen>
		<para>Операция монтирования предназначена для того, чтобы сделать доступной файловую систему, расположенную на каком-либо
			блочном устройстве. Суть операции монтирования заключается в том, что ядро ассоциирует некоторый каталог (называемый точкой 
			монтирования) с блочным устройством и драйвером файловой системы. Для этого оно передает ссылку на блочное устройство
			драйверу файловой системы, и в случае, если драйвер успешно проидентифицировал эту файловую систему, ядро заносит в
			специальную таблицу монтирования информацию о том, что все файлы и каталоги, чей полный путь начинается с указанной точки
			монтирования, обслуживаются соответствующим драйвером файловой системы и расположены на указанном блочном
			устройстве.</para>
		<para>Некоторые файловые системы не нуждаются в блочном устройстве, поскольку хранят свои данные исключительно в памяти,
			например файловая система procfs, через файлы которой можно получить доступ к различным системным параметрам и
			таблицам.</para>
		<para>Очень часто при монтировании файловой системы системный администратор имеет возможность задать опции монтирования.
			Опции монтирования – это специальные параметры, которые влияют на работу драйвера файловой системы, когда он работает с
			файловой системой на соответствующем блочном устройстве – например, с помощью опций монтирования можно управлять режимом
			кэширования данных, преобразованиями имен файлов и данных, включать и отключать поддержку ACL и т.д.</para>
		<para>Посмотреть таблицу примонтированных файловых систем можно через файл /proc/mounts:</para>
<screen>
$<userinput> cat /proc/mounts </userinput>
rootfs / rootfs rw 0 0
/dev/root / ext3 rw 0 0
none /dev devfs rw 0 0
/proc /proc proc rw,nodiratime 0 0
/sys /sys sysfs rw 0 0
none /dev/pts devpts rw 0 0
usbdevfs /proc/bus/usb usbdevfs rw 0 0
/dev/chimera/var /var ext3 rw 0 0
/dev/chimera/temp /tmp ext3 rw 0 0
/dev/chimera/usr /usr ext3 rw 0 0
/dev/chimera/home /home ext3 rw 0 0
/dev/chimera/opt /opt ext3 rw 0 0
none /dev/shm tmpfs rw 0 0
</screen>
	<para>Виртуальная файловая система Linux различает несколько типов файлов: каталоги, обычные файлы, именованные каналы,
		символьные ссылки, сокеты и специальные файлы. Каждая из этих разновидностей обрабатывается своим собственным образом:</para>
<orderedlist>
	<listitem>
		<para>Обычные файлы могут быть прочитаны, записаны, удалены или отображены в память.</para>
	</listitem>
	<listitem>
		<para>Каталог можно представить как список имен файлов, и для этого списка определены операции добавления элемента в список,
			удаление элемента из списка, переименование элемента списка.</para>
	</listitem>
	<listitem>
		<para>Именованные каналы являются просто буферами – в него можно записать некоторый объем данных, и прочесть их в том же
			порядке, в каком они были записаны.</para>
	</listitem>
	<listitem>
		<para>Сокеты являются вариантом именованных каналов, но если у именованного канала буфер только один, то есть нельзя определить
			какой процесс записал данные в канал, то у сокетов может быть несколько клиентов, один из которых осуществляет управление
			сокетом и может обмениваться данными с любым из остальных клиентов, а те в свою очередь могут обмениваться данными с
			диспетчером канала – то есть сокет поддерживает множество независимых буферов, по одному на каждую пару
			сервер+клиент</para>
	</listitem>
	<listitem>
		<para>Специальные файлы предназначены для того, чтобы осуществлять прямой доступ к устройствам. Подробнее о специальных
			файлах будет говориться в главе Секреты /dev</para>
	</listitem>
	<listitem>
		<para>Символьные ссылки являются “ярлыками”, которые могут содержать имя другого файла – и тогда операции чтения, записи и
			открытия/закрытия файла автоматически переадресовываются к файлу, на который указывает символьная ссылка, но в отличие от
			“ярлыков” Windows (shortcuts), символьные ссылки (symbolic links) не требуют специальных функций при работе – все программы
			(кроме тех, которые специально предназначены для работы с ними) видят их как обычные файлы, и также их открывают, читают и
			записывают данные и т.д.</para>
	</listitem>
</orderedlist>
		<para>В некоторых файловых системах, которые изначально проектировались для UNIX-подобных систем, есть возможность создавать
			кроме символьных ссылок еще и жесткие ссылки. Фактически, жесткая ссылка – это второе имя для файла. Жесткие ссылки
			возможно создавать только в пределах одной файловой системы.</para>
		<para>Из-за того, что в VFS присутствует понятие кэширования, перед отключением системы необходимо делать обязательный сброс
			изменений на диск. Сброс кэша на диск осуществляется в момент размонтирования файловой системы. Кроме того, с помощью
			команды	sync можно в любой момент принудительно сбросить на диск все закэшированные изменения в файловой системе
			(например, системные администраторы часто делают sync перед загрузкой нового драйвера). Размонтировать файловую систему
			можно только тогда, когда ни один процесс не удерживает в открытом состоянии файлов с этой файловой системы, а также не
			находится ни один процесс не имеет рабочим каталогом каталога с размонтируемой файловой системы. При невыполнении этого
			условия размонтировать файловую систему не удастся:</para>
<screen>
$<userinput> umount /home/ftp/pub/linux/fedora/cd1 </userinput>
umount: /home/ftp/pub/linux/fedora/cd1: device is busy
umount: /home/ftp/pub/linux/fedora/cd1: device is busy
</screen>
		<para>Некоторые файловые системы поддерживают специальные опции, позволяющие принудительно синхронизировать файловую
			систему при каждой операции чтения или записи. Обычно опции, влияющие на синхронизацию файловой системы, содержат в
			своем названии слово sync, например приведенная ниже команда инструктирует операционную систему примонтировать некоторый
			раздел в режиме принудительной синхронизации:</para>
<screen>
$<userinput> mount -t ext3 -o sync,dirsync /dev/hda9 /home </userinput>
</screen>
		<para>Следует учесть, что принудительная синхронизация – это удар по производительности операций записи для файловой системы,
			смонтированной в таком режиме, поэтому использовать такой его следует осторожно.</para>
	</section>
	<section xml:id="privileges">
		<info>
			<title>Права доступа</title>
		</info>
		<para>Кроме стандартных наборов прав доступа к файлам некоторые файловые системы Linux поддерживают т.н. POSIX ACL – списки
			контроля доступа POSIX. Эта возможность позволяет гибко управлять доступом к файлу, не ограничиваясь “классическим” набором
			ugo/rwx. Для того, чтобы использовать на файловой системе POSIX ACL, необходимо смонтировать файловую систему с опцией
			acl:</para>
<screen>
$<userinput>mount -t ext3 -o acl /dev/inferno/opt /opt</userinput>
</screen>
		<para>Возможно также настроить соответствующий параметр для файловой системы, чтобы она поддерживала POSIX ACL по
			умолчанию:</para>
<screen>
$<userinput> tune2fs -o acl /dev/inferno/opt</userinput>
</screen>
		<para>После установки соответствующей опции можно приступать к работе с POSIX ACL. Для работы с ними существует две базовых
		утилиты: getfacl для получения списка дополнительных атрибутов доступа, и setfacl для установки расширенных атрибутов контроля
		доступа. Если в выводе команды ls вы видите символ “+” рядом со списком стандартных прав доступа, это означает, что для файла также
		установлены 	расширенные атрибуты контроля доступа:</para>
<screen>
$<userinput> ls -l /home/dalth/.bash_???????</userinput>
-rw-r-----+ 1 dalth dalth 20034 Окт 11 22:48 /home/dalth/.bash_history
-rw-r--r--  1 dalth dalth   191 Авг 23 21:51 /home/dalth/.bash_profile
</screen>
		<para>Для просмотра значений расширенных атрибутов можно воспользоваться утилитой getfacl. Жирным шрифтом выделен
			дополнительный атрибут контроля доступа, позволяющий пользователю kiki получить доступ на чтение к файлу
			.bash_history:</para>
<screen>
$<userinput>getfacl .bash_history</userinput>
# file: .bash_history
# owner: dalth
# group: dalth
user::rw-
user:kiki:r--
group::---
mask::r--
other::---
</screen>
		<para>Добавим пользователю oracle права на чтение и запись файла .bash_history с помощью команды setfacl, и затем отберем
			дополнительные права на доступ к указанному файлу у пользователя kiki:</para>
<screen>
$<userinput>setfacl -m u:oracle:rw .bash_history</userinput>
$<userinput>setfacl -x u:kiki .bash_history</userinput>
$<userinput>getfacl .bash_history</userinput>
# file: .bash_history
# owner: dalth
# group: dalth
user::rw-
user:oracle:rw-
group::---
mask::rw-
other::---
</screen>
		<para>Последним шагом сбросим все расширенные атрибуты с файла с файла .bash_history:</para>
<screen>
$<userinput>setfacl -b .bash_history</userinput>
$<userinput>ls -l .bash_history</userinput>
$<userinput>getfacl .bash_history</userinput>
-rw-------  1 dalth dalth 20034 Окт 11 22:48 .bash_history
</screen>
		<para>Расширенные атрибуты позволяют гибко контролировать доступ к файловых объектам, обходя стратегию ugo/rwx пришедшую из
			“классического UNIX”. Права доступ на файловые объекты могут быть выданы не только пользователю, но и группе.</para>
		<para>К сожалению, далеко не все утилиты и файловые системы поддерживают ACL, поэтому при резервном копировании или
			восстановлении файлов необходимо проверять корректность установки расширенных атрибутов и правильность их
			переноса.</para>
	</section>
	<section xml:id="journal_file_system">
		<info>
			<title>Журналируемые файловые системы</title>
		</info>
		<para>Для обеспечения сохранности данных и обеспечения целостности файловых систем при неожиданных сбоях были разработаны
			журналируемые файловые системы. Как правило, у этих файловых систем существует специальная область данных, называемая
			журналом. Все изменения, которые необходимо произвести с файловой системой, сначала записываются в журнал, и уже из
			журнала попадают в основную часть файловой системы.</para>
		<para>В большинстве случаев журналируются только метаданные файловых систем (служебная информация, обеспечивающая
			целостность структуры файловой системы – например, изменения в каталогах или служебных таблицах размещения файлов).
			Некоторые файловые системы позволяют журналировать не только метаданные, но и данные файлов – такой шаг позволяет
			повысить надежность, но уменьшает скорость записи данных на файловую систему, поскольку каждый блок данных записывается
			на диск дважды – сначала в журнал, и затем из журнала в основную область файловой системы.</para>
		<para>В большинстве случаев, журналируемые файловые системы способны решить проблемы с надежностью при неожиданных сбоях
			без тех потерь производительности, к которым может привести использование опции sync при монтировании.</para>
		<para>В частности, к журналируемым файловым системам, например, относятся EXT3, ReiserFS, XFS, JFS и некоторые другие.</para>
	</section>
	<section xml:id="mapped_memory_files">
		<info>
			<title>Отображаемые в память файлы</title>
		</info>
		<para>Объединение кэширования файлов и разделяемой памяти позволяет реализовать такое действие, как отображение файла в
			память. Для простоты можно представить, что файл загружается в кэш, и страницы кэша отображаются в адресное пространство
			процесса, и в результате любое изменение в том фрагменте адресного пространства, которое занято отображением файла,
			автоматически попадает в закэшированные данные файла. Когда файл закрывается, закэшированные изменения сбрасываются на
			диск, изменяя сам файл. Кроме того, в свободное время ядро также постепенно сбрасывает изменившиеся кэшированные данные на
			диск.</para>
		<mediaobject>
			<imageobject>
				<imagedata fileref="images/mapped_memory_files.png" format="PNG"  width="60%" align="center"/>
			</imageobject>
			<textobject>
				<phrase>Files mapped in memory </phrase>	 
			</textobject>		
    		</mediaobject>
		<para>На самом деле, механизм отображения файлов в память куда “хитрее” - при обращении по записи к странице, которая является
			отображением некоторого файла, ядро перехватывает обращение, производит запись в файл (в подавляющем большинстве случаев
			эта операция попадает в кэш). При обращении по чтению к такой странице ядро опять же перехватывает обращение и производит
			чтение из файла – в большинстве случаев это чтение производится из кэша. Для наших же целей проще будет считать, что страницы
			кэша отображены в память процесса.</para>
		<para>Такая методика часто используется для загрузки разделяемых библиотек, когда выполняемый код библиотек и исполняемого кода
			программы хранится в кэше и через отображение файла в память становится виден в адресном пространстве процесса:</para>
<screen>
$<userinput>cat /proc/1/maps</userinput>
08048000-08050000 r-xp 00000000 03:01 75813      /sbin/init
08050000-08051000 rw-p 00008000 03:01 75813      /sbin/init
08051000-08072000 rw-p 08051000 00:00 0 
40015000-40016000 rw-p 40015000 00:00 0 
4c8ee000-4c903000 r-xp 00000000 03:01 92869      /lib/ld-2.3.3.so
4c903000-4c904000 r--p 00014000 03:01 92869      /lib/ld-2.3.3.so
4c904000-4c905000 rw-p 00015000 03:01 92869      /lib/ld-2.3.3.so
4c907000-4ca1c000 r-xp 00000000 03:01 92857      /lib/tls/libc-2.3.3.so
4ca1c000-4ca1e000 r--p 00115000 03:01 92857      /lib/tls/libc-2.3.3.so
4ca1e000-4ca20000 rw-p 00117000 03:01 92857      /lib/tls/libc-2.3.3.so
4ca20000-4ca22000 rw-p 4ca20000 00:00 0 
4d201000-4d20f000 r-xp 00000000 03:01 92965      /lib/libselinux.so.1
4d20f000-4d211000 rw-p 0000d000 03:01 92965      /lib/libselinux.so.1
bfffd000-c0000000 rw-p bfffd000 00:00 0 
ffffe000-fffff000 ---p 00000000 00:00 0 
</screen>
		<para>На самом деле, драйверы любого устройства и любой файловой системы могут по-своему реализовывать операцию mmap, но
			большинство драйверов файловых систем полагаются в этом на VFS.</para>
	</section>
	<section xml:id="special_file_systems">
		<info>
			<title>Специальные файловые системы</title>
		</info>
		<para>Некоторые типы файловых систем являются специальными и предназначаются для выполнения или реализации специфических
			задач операционной системы. К таким файловым системам относятся файловые системы procfs и sysfs, предоставляющие доступ к
			различным параметрам системы и системным объектам, “живущим” в ядре.</para>
		<para>Файловая система sysfs в основном предоставляет доступ к объектам ядра и отображает взаимосвязи между ними. Файловая
			система procfs предоставляет доступ к различным параметрам ядра и драйверов и к пользовательским процессам, позволяя тем
			самым реализовать такие команды как ps или sysctl. Большинство файлов в sysfs двоичные, в procfs – текстовые.</para>
		<para>Драйверы файловых системы ramfs, tmpfs и shmfs очень похожи, и после монтирования файловой системы такого типа на ней
			можно создавать файлы, хранящиеся в памяти и отличаются в основном небольшими особенностями работы (например, страницы,
			используемые ramfs под данные файлов, не вытесняются в swap-файл в отличие от shmfs и tmpfs). В ядре 2.6 shmfs была заменена
			на tmpfs.</para>
	</section>
	<section xml:id="network_file_systems">
		<info>
			<title>Сетевые файловые системы</title>
		</info>
		<para>Сетевые файловые системы предназначены для получения доступа к файловым системам других компьютеров с использованием
			сетевых протоколов.</para>
		<para>Наиболее часто используются сетевые файловые системы NCPFS (для доступа к серверам Novell NetWare), SMBFS (для доступа к
			серверам Windows) и NFS (для доступа к файловым системам других UNIX-систем).</para>
		<para>Как правило, процедура монтирования сетевых файловых систем схожа с процедурой монтирования обычных файловых систем
			на блочных устройствах с тем отличием, что вместо блочного устройства указывается адрес сервера, чья файловая система
			монтируется, и имя монтируемого ресурса. Для примера рассмотрим процедуры монтирования ресурсов, доступных по SMB и по
			NFS:</para>
<screen>
$<userinput>mount -t smbfs -o username=usr,workgroup=tst //server/share_name /mnt/smb_target</userinput>
Password: ********
$<userinput>mount -t nfs -o timeout=4 server:/export/home /mnt/nfs_target</userinput>
</screen>
		<para>В данном примере опция -t команды mount указывает тип файловой системы, опция -o позволяет задать дополнительные
			параметры для монтирования – для SMB мы задаем, например, имя пользователя, с правами которого производится подключение к
			серверу и имя рабочей группы или домена, для NFS мы указываем таймаут, по истечении которого операция ввода/вывода считается
			неудавшейся. Вместо блочного устройства мы указываем адрес сервера, ресурс которого хотим использовать, и имя ресурса на
			сервере. Последним параметром идет точка монтирования.</para>				
	</section>
    <section xml:id="create_file_systems">
       <info>
           <title>Создание файловых систем</title>
       </info>
       <para>Для создания файловых систем в Linux используется команда mkfs:</para>
<screen>
$<userinput>mkfs -t ext3 /dev/hda6</userinput>
</screen> 
       <para>  На самом деле, mkfs является просто “оберткой” к реальным программам создания файловых систем, которые обычно именуются как mkfs.&lt;имя_ФС&gt;, 
         например mksf.ext2 или mkfs.reiserfs.</para>
       <para>В большинстве случаев программы группы mkfs просто инициализируют специальную область раздела, называемую суперблоком файловой системы. Суперблок 
         содержит ссылки на все значимые элементы файловой системы (например,ссылку на оглавление корневого каталога, ссылку список свободных блоков, ссылку
          на список файлов и т.д.)</para>
        <para>Наличие суперблока (который практически всегда содержит в своем теле некоторое характерное значение) позволяет производить монтирование файловых
         систем без указания их типа. К сожалению, некоторые файловые системы вследствие своей архитектуры не содержат суперблока (в частности, FAT и 
         большинство ее разновидностей) и для блочных устройств, содержащих такие файловые системы, автоматическое определение типа файловой системы
         затруднено.</para> 
     </section>
     </section>
     <section xml:id="static_and_dynamic_programs">
       <info>
           <title>Статически и динамически собранные программы</title>
       </info>
       <para>В Linux исполняемые файлы можно условно разделить на две группы – те, которые содержат в себе весь код, необходимые для работы, и те, которым 
       необходимы разделяемые библиотеки. Первые называют статически собранными бинарными файлами, вторые называют динамически собранными исполняемыми
       файлами.</para>
       <para>Статически собранные программы характеризуются тем, что могут корректно функционировать в любых условиях, и не зависят от наличия или отсутствия
       разделяемых библиотек, что может оказаться полезным в ситуациях, когда возникают конфликты версий разделяемых библиотек, или когда системные
       библиотеки повреждены или недоступны (например во время восстановления операционной системы после серьезного сбоя). К недостаткам таких исполняемых 
       файлов следует отнести то, что они имеют значительный размер и для обновления программы необходимо полностью заменить ее исполняемый файл – например, 
       если несколько статически собранных программ, которые работают с архивами ZIP, содержат ошибку, то для исправления ошибки необходимо заменить все эти 
       программы, что может быть затруднено (например, будет трудно точно установить, какие именно программы содержат ошибочный код и нуждаются в обновлении).
       Кроме того, статически собранные программы не умеют совместно использовать совпадающие участки кода, что ведет к излишнему расходу системных ресурсов.
       </para>
       <para>Динамически собранные исполняемые файлы для корректной работы требуют наличия файлов разделяемых библиотек, и соответственно при их
        отсутствии/повреждении не могут корректно функционировать, но зато для обновления программы и исправления ошибки часто оказывается достаточным 
        просто заменить соответствующую разделяемую библиотеку, после чего ошибка исчезает во всех программах, которые эту библиотеку используют динамически.
        Динамически связанные программы также значительно меньше по объему, чем статически связанные, и код разделяемых библиотек может использоваться 
        одновременно многими программами – что позволяет экономить системные ресурсы.</para>
       <para>Подавляющее большинство программ в современных дистрибутивах Linux являются динамически собранными. Определить тип исполняемого фала
       (статический ли он либо с динамическим связыванием) можно, например, с помощью команды ldd:</para>
<screen>
$<userinput>ldd /bin/su</userinput>
linux-gate.so.1 =>  (0xffffe000)
libpam.so.0 => /lib/libpam.so.0 (0x4ce08000)
libpam_misc.so.0 => /lib/libpam_misc.so.0 (0x4cb3c000)
libcrypt.so.1 => /lib/libcrypt.so.1 (0x4e3a2000)
libdl.so.2 => /lib/libdl.so.2 (0x4ca49000)
libc.so.6 => /lib/tls/libc.so.6 (0x4c907000)
/lib/ld-linux.so.2 => /lib/ld-linux.so.2 (0x4c8ee000)
$<userinput>ldd /sbin/devlabel</userinput>
not a dynamic executable
</screen>
      <para>В данном случае мы видим, что исполняемый файл /bin/su использует динамическое связывание, а исполняемый файл /sbin/devlabel собран
       статическим образом.</para>
       </section>
      <section xml:id="glibc">
       <info>
           <title>Системная библиотека GNU libc</title>
       </info>
       <para>Основная системная библиотека, которая так или иначе используется практически всеми программами, называется glibc (GNU libc). 
       Основными задачами glibc являются обеспечение взаимодействия между ядром и пользовательскими процессами, поддержка локализации и 
       многие другие распространенные действия.</para>
       <para>На нижнем уровне прикладные процессы могут обратиться к функциям ядра посредством системных вызовов (syscall). Фактически syscall – это
        вызов прерывания 80h  с установленными параметрами, описывающими параметры для этого системного вызова. Те функции glibc, которые должны обратиться
        к ядру, в большинстве случаев просто устанавливают параметры для соответствующего системного вызова и вызывают int80h.</para>
       <para>Большинство программ используют динамически загружаемую библиотеку glibc, но некоторые приложения, которые должны работать вне
        зависимости от наличия файловой системы, где расположена динамически загружаемая реализация libc, используют статическое связывание, 
        когда весь программный код, необходимый для их работы, содержится в исполняемом файле программы. В основном к таким программам относятся
        утилиты, используемые при загрузке системы совместно с initrd – например, статические варианты утилит insmod, lvm или devlabel, а также
        командные оболочки для первичной зарузки или восстановления системы – например sash – standalone shell, часто используемый при восстановлении
        системы после серьезного сбоя или nash, используемый при выполнении сценариев загрузки после монтирования initrd, но до монтирования корневой
        файловой системы, когда разделяемая версия glibc еще недоступна.</para>
       </section>
       <section xml:id="ld_shared_libs_so_and_more">
       <info>
           <title>LD, Shared Library, SO и много страшных слов</title>
       </info>
        <para>Существует набор базовых действий, которые практически любая программа выполняет одинаково – открытие файла, чтение и запись данных
         и тому подобное. Разделяемые библиотеки предназначены для того, чтобы предоставить прикладным программам готовые интерфейсы функций для 
         выполнения каких-либо более-менее стандартных действий. Разделяемая библиотека, как понятно из названия, может использоваться множеством
         программ. В настоящий момент стандартным форматом для разделяемых библиотек в Linux является ELF (Executable Linked Format).</para>
         
         <para>Каждый файл ELF имеет заголовок, в котором описывается, какие секции содержит этот файл. Секции объединяют однотипные данные, и их
         детальное описание можно прочитать в справочном руководстве [man elf]. Мы же выделим следующую информацию: каждая библиотека содержит список
         имен переменных и функций, которые она содержит и предоставляет другим (экспортирует) и список переменных и функций, которые необходимо взять
         в других библиотеках, а также секции инициализации и деинициализации. Экспортируемые и импортируемые объекты (переменные и функции) называют
         символами библиотеки.</para>
         
         <para>Большинство исполняемых файлов программ также имеют формат ELF, и на самом деле отличаются от библиотек в основном тем, что не имеют
         экспортируемых функций. Загрузчик ELF (он же dl, dynamic linker и dynamic loader) умеет загружать в память код ELF-файла, анализировать его
         структуру для определения списков экспортируемых и импортируемых символов и загружать необходимые для работы программы библиотеки.</para>
         
         <para>Когда пользователь пытается запустить какую–либо программу, первым начинает работу загрузчик ELF. Он загружает в память процесса бинарный
         файл и выделяет, какие символы и из каких библиотек необходимо догрузить в память. После дозагрузки каждой библиотеки загрузчик связывает
         символы (проставляет реальные адреса) из загруженной библиотеки и повторяет цикл анализа на предмет того, какую библиотеку нужно загрузить.
         Когда все нужные библиотеки загружены, загрузчик передает управление коду инициализации каждой из загруженных библиотек в порядке, обратном
         загрузке, после чего передает управление коду программы. По завершении программы загрузчик снова “проходится” по всем библиотекам и вызывает
         их функции деинициализации. Если на этапе загрузки какой – либо библиотеке возникает ошибка, загрузчик сообщит об этом пользователю. Наиболее
         типичные ошибки dl – это не найденный файл библиотеки или неразрешимый символ (символ не был найден в библиотеке, в которой ожидался).</para>
         
         <para>Вполне естественно, что загрузчик ищет библиотеки не по всей файловой системе, а только в определенных каталогах. Это каталоги /lib,
         /usr/lib и те, которые были перечислены системным администратором в файле /etc/ld.so.conf. Уточним, что этот файл на самом деле используется
         только системной утилитой ldconfig, сам же загрузчик использует кэш-файл /etc/ld.so.cache. Обновить этот кэш-файл можно путем простого запуска
         ldconfig без параметров. Следствием этого является то, что если вы установили в систему новые библиотеки, не мешает вызвать ldconfig.</para>
   
         <para>В некоторых дистрибутивах есть возможность включать в ld.so.conf дополнительные файлы без его изменения. Для этого в ld.so.conf
         включается специальная строка вида:</para>
<screen>
include ld.so.conf.d/*.conf
</screen>
         <para>Это приводит к тому, что каталоги, перечисленные в файлах с расширением conf, расположенных  в каталоге /etc/ld.so.conf.d будут
         использованы для поиска разделяемых библиотек:</para>
<screen>
$<userinput>cat /etc/ld.so.conf</userinput>
include ld.so.conf.d/*.conf
/usr/lib/mysql
/usr/X11R6/lib
/usr/lib/qt-3.3/lib
$<userinput>ls /etc/ld.so.conf.d/</userinput>
oracle
$<userinput>cat /etc/ld.so.conf.d/oracle</userinput>
/opt/oracle/9i/lib
</screen>
       <para>Нередко возникает ситуация, когда пользователю необходимо запустить какую-либо программу, которая не находится в каталогах,
       описанных в /etc/ld.so.conf. В таких ситуациях можно воспользоваться специальным “люком”, оставленным разработчиками dl специально
       для таких случаев: дело в том, что кроме загрузки библиотек с использованием данных из ld.so.cache загрузчик проверяет факт наличия
       библиотеки с указанным именем в каталогах, перечисленных в переменной среды LD_LIBRARY_PATH.</para>
       
       <para>Разработчики часто используют еще одну возможность ld: если файл некоторой разделяемой библиотеки указан в переменной LD_PRELOAD,
       эта библиотека принудительно загружается и ее символы считаются более “приоритетными” и перекрывают одноименные символы, если таковые
       существуют в других библиотеках, загружаемых ld при запуске на выполнение бинарного файла ELF.</para>
       
       <para>Попробуем рассмотреть примеры использования указанных возможностей dl: пусть есть некоторый программный продукт, в состав которого
       кроме собственно исполняемых программ входят разделяемые библиотеки (например, таковы практически все продукты, разработанные с
       помощью Borland Kylix). Если мы установим такой пакет, например, в /opt/program, его исполняемые файлы в /opt/program/bin а разделяемые
       библиотеки в /opt/program/lib, то программа, скорее всего, не будет запускаться, поскольку не сможет загрузить необходимых библиотек. Для того,
       чтобы программы пакета начали запускаться, мы должны “объяснить” ld где именно искать библиотеки. Рассмотрим возможные способы, которыми
       мы можем воздействовать на ld чтобы добиться нужного нам результата.</para>
       
       <para>Первый способ – указать каталог с библиотеками перед запуском программы и уже затем запустить программу (ld воспользуется значением
       переменной для того, чтобы попытаться найти библиотеки по указанному пути):</para>
<screen>
$<userinput>export LD_LIBRARY_PATH=/opt/program/lib</userinput>
$<userinput>/opt/program/bin/filename</userinput>
</screen>       
       <para>Второй способ – добавить каталог /opt/program/lib в файл /etc/ld.so.conf и запустить ldconfig, решив проблему с невозможностью
       нахождения этих библиотек для всех программ сразу:</para>
<screen>
$<userinput>su -</userinput>
#<userinput>echo /opt/program/lib >>/etc/ld.so.conf</userinput>
#<userinput>ldconfig</userinput>
#<userinput>exit</userinput>
$<userinput>/opr/program/bin/filename</userinput>
</screen>       
       <para>Можно также воспользоваться возможностью принудительной загрузки тех библиотек, которые необходимы программе для запуска:</para>
<screen>
$<userinput>export LD_PRELOAD=/opt/program/lib/*$ /opr/program/bin/filename</userinput>
</screen>       
       <para>Большая часть кода разделяемых библиотек находится в кэше и становится доступна процессам через отображение файла в память.
       Это отображение делается с правами доступа “только чтение”, что защищает код библиотек от переписывания его неправильно работающими
       или просто злонамеренными программами.</para>       
       </section>
       <section xml:id="processes_information">
       <info>
           <title>Информация о процессах и файловая систем /proc</title>
       </info>
       <para>Ядро и его подсистемы очень важны, но большинство пользы приносят прикладные задачи, поэтому мониторинг состояния задач 
       (процессов) – очень важная часть работы системного администратора. В Linux получить информацию о процессах можно через файлы и
       каталоги файловой системы procfs, как правило монтируемой к каталогу /proc.</para>
       
       <para>Каждому процессу сопоставляется в /proc отдельный каталог, имя которого совпадает со значением PID процесса. Файлы в этом
       каталоге предоставляют информацию о соответствующем процессе. Таблица приводит список файлов и их назначение:</para>
       
   <informaltable frame="all" pgwide="1">
      <tgroup cols="3">
         <thead>
            <row>
               <entry>
                  <para>Имя файла</para>
               </entry>
               <entry>
                  <para>Формат</para>
               </entry>
               <entry>
                  <para>Назначение</para>
               </entry>
            </row>
         </thead><tbody><row>
            <entry>
               <para>cmdline</para>
            </entry>
            <entry>
               <para>строка, разделенная символами \0</para>
            </entry>
            <entry>
               <para>Представляет командную строку, которой был запущен процесс. Параметры командной строки отделяются друг от друга символами \0</para>
            </entry>
         </row>
         <row>
            <entry>
               <para>environ</para>
            </entry>
            <entry>
               <para>строка, разделенная символами \0</para>
            </entry>
            <entry>
               <para>Представляет список переменных окружения для указанного процесса</para>
            </entry>
         </row>
         <row>
            <entry>
               <para>exe</para>
            </entry>
            <entry>
               <para>символьная ссылка</para>
            </entry>
            <entry>
               <para>Ссылается на исполняемый файл процесса</para>
            </entry>
         </row>
         <row>
            <entry>
               <para>maps</para>
            </entry>
            <entry>
               <para>несколько строк</para>
            </entry>
            <entry>
               <para>Список отображенных в память процесса файлов</para>
            </entry>
         </row>
         <row>
            <entry>
               <para>mem</para>
            </entry>
            <entry>
               <para>бинарный</para>
            </entry>
            <entry>
               <para>Прямой доступ к адресному пространству процесса</para>
            </entry>
         </row>
         <row>
            <entry>
               <para>mounts</para>
            </entry>
            <entry>
               <para>несколько строк</para>
            </entry>
            <entry>
               <para>Список примонтированных файловых систем, доступных процессу</para>
            </entry>
         </row>
         <row>
            <entry>
               <para>stat</para>
            </entry>
            <entry>
               <para>строка числовых значений</para>
            </entry>
            <entry>
               <para>Статистика активности процесса</para>
            </entry>
         </row>
         <row>
            <entry>
               <para>statm</para>
            </entry>
            <entry>
               <para>строка числовых значений</para>
            </entry>
            <entry>
               <para>Статистика по использованию памяти процессом</para>
            </entry>
         </row>
         <row>
            <entry>
               <para>cwd</para>
            </entry>
            <entry>
               <para>символьная ссылка</para>
            </entry>
            <entry>
               <para>Ссылается на каталог, который является текущим для процесса</para>
            </entry>
         </row>
         <row>
            <entry>
               <para>fd/*</para>
            </entry>
            <entry>
               <para>символьные ссылки</para>
            </entry>
            <entry>
               <para>Имена файлов подкаталога fd соответсвуют открытым процессом дескрипторам файлов. Символьные ссылки указывают на соответствующие файлы</para>
            </entry>
         </row>
         <row>
            <entry>
               <para>root</para>
            </entry>
            <entry>
               <para>символьная ссылка</para>
            </entry>
            <entry>
               <para>Ссылается на каталог, который процесс считает корневым</para>
            </entry>
         </row>
         <row>
            <entry>
               <para>status</para>
            </entry>
            <entry>
               <para>несколько строк</para>
            </entry>
            <entry>
               <para>Описание состояния процесса</para>
            </entry>
         </row></tbody></tgroup>
      </informaltable>
          <para>Все указанные данные полностью соответствуют тому, что показала бы программа ps, будучи запущеной в тот момент, когда
          просматривается соответствующий файл, поскольку утилита ps на самом деле просто читает данные из соответствующих файлов в /proc.</para>
       </section>
       <section xml:id="sysctl">
       <info>
           <title>Интерфейс sysctl</title>
       </info>
       <para>Ядро содержит очень много параметров, от которых зависит его производительность и которые могут изменять алгоритмы его работы.
       Для того, чтобы иметь возможность узнавать и изменять эти параметры, в UNIX был разработан интерфейс sysctl.</para>
       
       <para>Виртуальная файловая система procfs содержит каталог sys с деревом подкаталогов и файлов. Содержимое каждого из этих файлов
       можно прочесть, например, командой cat, или записать в такой файл новое значение командой echo:</para>
<screen>
$<userinput>cat /proc/sys/kernel/shmmax</userinput>
33554432
$<userinput>echo 67108864 &gt;/proc/sys/kernel/shmmax</userinput>
$<userinput>cat /proc/sys/kernel/shmmax</userinput>
67108864
</screen>
       <para>Команда sysctl предназначена для того, чтобы избежать необходимости использовать прямой доступ к этим файлам, и предоставить
       возможность автоматизации установки таких параметров при загрузке системы. На самом же деле, команда sysctl просто читает или
       записывает значения в файлы из каталога /proc/sys, т.е. если системный администратор устанавливает с помощью команды sysctl
       значение некоторого параметра, фактически он просто записывает это значение в соответствующий файл. Существует однозначное соответствие
       между именем параметра и именем файла, через который его можно изменить:  если посмотреть вывод sysctl -a, можно увидеть, что параметры
       в большинстве своем именуются несколькими мнемоническими аббревиатурами, разделенными точками:</para>
<screen>
$<userinput>sysctl -a | grep mem</userinput>
net.ipv4.tcp_rmem = 4096        87380   174760
net.ipv4.tcp_wmem = 4096        16384   131072
net.ipv4.tcp_mem = 24576        32768   49152
net.ipv4.igmp_max_memberships = 20
net.core.optmem_max = 10240
net.core.rmem_default = 108544
net.core.wmem_default = 108544
</screen>
      <para>Если в имени параметра заменить точки на символ разделителя пути (символ “/”), и к началу получившейся строки добавить /proc/sys/
      - то мы получим имя файла, через который можно изменить или прочесть значение соответствующего параметра.</para>
      
      <para>Если системному администратору необходимо при каждой загрузке изменять некоторые параметры через интерфейс sysctl, то список
      параметров и их значений можно записать в конфигурационный файл /etc/sysctl.conf, который прочитывается при каждой загрузке системы.</para>
     </section>
       <section xml:id="create_processes">
       <info>
           <title>Создание процессов</title>
       </info>
       <para>Linux на самом деле поддерживает только один внутренний механизм создания процессов – механизм fork+exec. Любой процесс,
       который хочет создать еще один процесс, должен сначала создать свою копию с помощью системного вызова fork, после чего порожденный
       процесс, который является полной копией предыдущего за исключением нескольких параметров, таких как PID (Process ID) и PPID
       (Parent Process ID) использует системный вызов exec для того, чтобы загрузить в свое адресное пространство код новой программы
       и начать его выполнение. Соответственно, все процессы организуют дерево, когда у каждого процесса есть родительский процесс
       (исключение составляет процесс init, запущеный ядром на этапе загрузки).</para>
       
       <para>Когда процесс завершается, код его завершения возвращается родительскому процессу. До тех пор, пока код завершения процесса
       не будет прочитан родительским процессом, запись об этом процессе продолжает существовать в таблице процессов в ядре. Такой
       процесс (уже завершившийся, но еще числящийся в таблице процессов) называют процессом – зомби (zombie process). Завершить zombie
       process может родительский процесс, прочтя код его завершения. Если у вас в системе появилось множество зомби – процессов, это
       скорее всего означает ошибку в программе, породившей этот процесс. Удалить процесс – зомби можно только удалив его родительский процесс.</para>
       
       <para>Нередко бывает, что родительский процесс завершается раньше, чем дочерний, и тогда для дочернего процесса объявляется
       родительским процесс init, и поэтому в системе никогда не бывает процессов-”сирот”, т.е. тех, кто не имеет родителя и чей код
       завершения некому прочесть.</para>
       </section>
</article>